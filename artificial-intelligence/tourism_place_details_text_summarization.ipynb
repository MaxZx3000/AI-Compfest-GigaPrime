{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tourism_place_details_text_summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQxZVOz6jIniLKYtIM0dN6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tourism Place Details Text Summarization"
      ],
      "metadata": {
        "id": "RiRausmOc3Yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Import"
      ],
      "metadata": {
        "id": "gWWfELVudPvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5_ot7H1rsmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd07cb8-d292-4974-b45d-8b2a83ab871e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.12.0.tar.gz (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 15.7 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 42.1 MB/s \n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->nlp-id) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.7.3)\n",
            "Building wheels for collected packages: nlp-id, nltk, wget\n",
            "  Building wheel for nlp-id (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp-id: filename=nlp_id-0.1.12.0-py3-none-any.whl size=8074104 sha256=247890b0183414ff19ea731a79d8c7f1a8bf9b62c0bfb339887f04fc35e23e06\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/50/48/da59531125bd94f48dfe66140f41d8fd8a4f04062050375013\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=028348e3ccc06998c4d133e05725f5b11cfbcd43e22e5bf7568b4291c4d93d97\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=4623abe40273bb1f4bf286d07d32e2f9f108145c9307a7ceb9316ac28e38d62b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built nlp-id nltk wget\n",
            "Installing collected packages: wget, scikit-learn, nltk, nlp-id\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22 which is incompatible.\u001b[0m\n",
            "Successfully installed nlp-id-0.1.12.0 nltk-3.4.5 scikit-learn-0.22 wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install nlp-id\n",
        "! pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from bs4 import BeautifulSoup\n",
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "from nlp_id.tokenizer import Tokenizer\n",
        "from nltk import sent_tokenize, word_tokenize, treebank\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "google_url = \"https://www.googleapis.com/customsearch/v1?key=AIzaSyAsQSjiOTOUOqz-oRrp71bdmHmoa9eLqyc&cx=e34228993d08f4238&q=Monumen+Nasional+Berita\"\n",
        "google_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "VxNfiAxukL9W",
        "outputId": "442b390e-7b01-4a48-c58a-80a8ee58dc7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.googleapis.com/customsearch/v1?key=AIzaSyAsQSjiOTOUOqz-oRrp71bdmHmoa9eLqyc&cx=e34228993d08f4238&q=Monumen+Nasional+Berita'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}